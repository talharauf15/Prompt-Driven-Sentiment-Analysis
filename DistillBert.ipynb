{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "W9uH58M_F9hQ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"distilbert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_sentiment_analysis(prompt):\n",
        "    sentiment_prompt = f\"The sentiment of this text is either positive, negative, or neutral: {prompt} Sentiment:\"\n",
        "\n",
        "    inputs = tokenizer(sentiment_prompt, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Extract last 3 logits (assuming they correspond to sentiment classes)\n",
        "    # Get the logits for the [MASK] token (usually the first token in the input)\n",
        "    sentiment_scores = logits[0, -1, -3:]  # Assuming [MASK] is the last token\n",
        "\n",
        "    sentiment_idx = torch.argmax(sentiment_scores).item()\n",
        "\n",
        "    sentiment_mapping = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
        "    sentiment = sentiment_mapping[sentiment_idx]\n",
        "\n",
        "    return sentiment"
      ],
      "metadata": {
        "id": "k_Tu2UHZGFIx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"I absolutely love this product. It's fantastic!\"\n",
        "sentiment = perform_sentiment_analysis(example)\n",
        "print(f\"Predicted Sentiment: {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7GoE9pJMOci",
        "outputId": "30e2ebe2-ef4a-48b8-9803-ba626856b2ff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"this product is okey!\"\n",
        "sentiment = perform_sentiment_analysis(example)\n",
        "print(f\"Predicted Sentiment: {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFkokrepNXHL",
        "outputId": "0682aa2a-2ba8-4a44-cd67-a5edfaac0365"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"This product is trash!\"\n",
        "sentiment = perform_sentiment_analysis(example)\n",
        "print(f\"Predicted Sentiment: {sentiment}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y633FCbJNWrH",
        "outputId": "bcddf48e-357b-444e-8fc4-14dc030830e1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Sentiment: positive\n"
          ]
        }
      ]
    }
  ]
}